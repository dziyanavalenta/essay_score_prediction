{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc9fb68-3923-4c10-89aa-096db2abf9e3",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Summary of Steps](#Summary-of-Steps)\n",
    "- [Imports](#Imports)\n",
    "- [Classification Models](#Classification-Models)\n",
    "  - [Numerical Features](#Numerical-Features)\n",
    "  - [TF-IDF Features](#TF-IDF-Features)\n",
    "  - [Combined Numerical and TF-IDF Features](#Combined-Numerical-and-TF-IDF-Features)\n",
    "- [Regression Models](#Regression-Models)\n",
    "  - [Numerical Features](#Numerical-Features)\n",
    "  - [TF-IDF Features](#TF-IDF-Features)\n",
    "  - [Combined Numerical and TF-IDF Features](#Combined-Numerical-and-TF-IDF-Features)\n",
    "- [Word2Vec Features](#Word2Vec-Features)\n",
    "  - [Option 1: Traditional Machine Learning Classification Models](#Option-1:-Traditional-Machine-Learning-Classification-Models)\n",
    "  - [Option 2: Traditional Machine Learning Regression Models](#Option-2:-Traditional-Machine-Learning-Regression-Models)\n",
    "  - [Option 3: Using Neural Networks](#Option-3:-Using-Neural-Networks)\n",
    "- [BERT](#BERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411c23c-36d2-45b1-9a3c-daf074e70398",
   "metadata": {},
   "source": [
    "## Summary of Steps\n",
    "\n",
    "1. **Load Data:** Load the `numeric_features_added_v1.csv`.\n",
    "2. **Define Features:** Define the numerical features and extract them from the DataFrame.\n",
    "3. **Split Data:** Split the data into training and test sets.\n",
    "4. **Train Model:** Train the `CatBoostRegressor` on the training data.\n",
    "5. **Predict:** Make predictions on the test data.\n",
    "6. **Discretize Predictions:** Discretize both the predictions and the actual test labels.\n",
    "7. **Evaluate:** Compute the Quadratic Weighted Kappa Score to evaluate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7175f84f-7c00-49ae-a709-18deeefa130d",
   "metadata": {},
   "source": [
    "Note: Light GBM is commented because it generates logs. Model was evaluated and commented later as it was not the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2761ea-a83e-4971-b5c2-75f5c90a8623",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e49157c-df91-428e-bfb6-8f7208fe3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b37d2b8-4acc-42b9-bc29-723feea011bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877eeb38-3448-4a47-9b7b-808d26337a13",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6130c6-360b-4204-90ff-37baa192ff85",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "385e6119-cffa-42d3-b103-f3faf13b2d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "1    4294\n",
      "2    4017\n",
      "3    2513\n",
      "4    2194\n",
      "0     854\n",
      "5     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "1    1074\n",
      "2    1005\n",
      "3     628\n",
      "4     548\n",
      "0     214\n",
      "5     142\n",
      "Name: count, dtype: int64\n",
      "Working on Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dziya\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for Logistic Regression: 6.297773838043213 seconds\n",
      "Distinct predicted values on training set for Logistic Regression: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for Logistic Regression: [1 2 3 4 5 6]\n",
      "Working on Random Forest Classifier...\n",
      "Elapsed time for Random Forest Classifier: 11.210044860839844 seconds\n",
      "Distinct predicted values on training set for Random Forest Classifier: [2 3 4 5 6]\n",
      "Distinct predicted values on test set for Random Forest Classifier: [2 3 4 5 6]\n",
      "Working on AdaBoost Classifier...\n",
      "Elapsed time for AdaBoost Classifier: 2.1219630241394043 seconds\n",
      "Distinct predicted values on training set for AdaBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for AdaBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on CatBoost Classifier...\n",
      "Elapsed time for CatBoost Classifier: 4.910132169723511 seconds\n",
      "Distinct predicted values on training set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on XGBoost Classifier...\n",
      "Elapsed time for XGBoost Classifier: 8.252674102783203 seconds\n",
      "Distinct predicted values on training set for XGBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for XGBoost Classifier: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Load the training and test datasets\n",
    "df = pd.read_csv('numeric_features_added_exp_2.csv')\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = [\n",
    "    'reading_time',\n",
    "    'mistakes_dist_ratio',\n",
    "    'polysyllabcount',\n",
    "    'sentence_count',\n",
    "    'difficult_words',\n",
    "    'comma_count',\n",
    "    'transitional_phrases_c',\n",
    "    'text_dist_words_ratio'\n",
    "]\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = df[numerical_features]\n",
    "y = df['score'] - 1  # Adjust class labels to start from 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=600, max_depth=4, random_state=42),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'CatBoost Classifier': CatBoostClassifier(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Classifier': XGBClassifier(objective='multi:softmax', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Classifier': LGBMClassifier(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on training set for {name}: {np.unique(y_train_pred)}\")\n",
    "    kappa_train_score = cohen_kappa_score(y_train + 1, y_train_pred, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on test set for {name}: {np.unique(y_test_pred)}\")\n",
    "    kappa_test_score = cohen_kappa_score(y_test + 1, y_test_pred, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbc9c937-8d7d-47b4-8321-4bea7746c481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  QWK Score (Train)  QWK Score (Test)\n",
      "3       CatBoost Classifier           0.840578          0.833498\n",
      "4        XGBoost Classifier           0.836412          0.828504\n",
      "0       Logistic Regression           0.805838          0.812265\n",
      "1  Random Forest Classifier           0.808717          0.810941\n",
      "2       AdaBoost Classifier           0.633158          0.634854\n"
     ]
    }
   ],
   "source": [
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(by='QWK Score (Test)', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a52927b-5982-4847-972a-412c7fbf0aa6",
   "metadata": {},
   "source": [
    "### TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37914218-cc40-4ecb-969e-18f4dedb62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "1    4294\n",
      "2    4017\n",
      "3    2513\n",
      "4    2194\n",
      "0     854\n",
      "5     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "1    1074\n",
      "2    1005\n",
      "3     628\n",
      "4     548\n",
      "0     214\n",
      "5     142\n",
      "Name: count, dtype: int64\n",
      "Working on Logistic Regression...\n",
      "Elapsed time for Logistic Regression: 5.57770562171936 seconds\n",
      "Distinct predicted values on training set for Logistic Regression: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for Logistic Regression: [1 2 3 4 5 6]\n",
      "Working on CatBoost Classifier...\n",
      "Elapsed time for CatBoost Classifier: 112.0259006023407 seconds\n",
      "Distinct predicted values on training set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on XGBoost Classifier...\n",
      "Elapsed time for XGBoost Classifier: 219.37614035606384 seconds\n",
      "Distinct predicted values on training set for XGBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for XGBoost Classifier: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "# Load the datasets\n",
    "df_transformed = pd.read_csv('transformed_data_exp_2.csv')\n",
    "df_tfidf = pd.read_csv('tfidf_features_exp_2.csv')\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = df_tfidf\n",
    "y = df_transformed['score'] - 1  # Adjust class labels to start from 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    #'Random Forest Classifier': RandomForestClassifier(n_estimators=600, max_depth=4, random_state=42),\n",
    "    #'AdaBoost Classifier': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'CatBoost Classifier': CatBoostClassifier(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Classifier': XGBClassifier(objective='multi:softmax', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Classifier': LGBMClassifier(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on training set for {name}: {np.unique(y_train_pred)}\")\n",
    "    kappa_train_score = cohen_kappa_score(y_train + 1, y_train_pred, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on test set for {name}: {np.unique(y_test_pred)}\")\n",
    "    kappa_test_score = cohen_kappa_score(y_test + 1, y_test_pred, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be600ae8-4c25-442c-a529-33f12cdb3c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  QWK Score (Train)  QWK Score (Test)\n",
      "0  Logistic Regression           0.793493          0.739610\n",
      "2   XGBoost Classifier           0.993676          0.712289\n",
      "1  CatBoost Classifier           0.833477          0.696338\n"
     ]
    }
   ],
   "source": [
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(by='QWK Score (Test)', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a2a6a-207d-455a-9b6d-0388032dd7ad",
   "metadata": {},
   "source": [
    "### Combined Numerical and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccc6649c-0190-44c1-b3e2-0861967eb372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "1    4294\n",
      "2    4017\n",
      "3    2513\n",
      "4    2194\n",
      "0     854\n",
      "5     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "1    1074\n",
      "2    1005\n",
      "3     628\n",
      "4     548\n",
      "0     214\n",
      "5     142\n",
      "Name: count, dtype: int64\n",
      "Working on CatBoost Classifier...\n",
      "Elapsed time for CatBoost Classifier: 60.9344277381897 seconds\n",
      "Distinct predicted values on training set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on XGBoost Classifier...\n",
      "Elapsed time for XGBoost Classifier: 214.78234338760376 seconds\n",
      "Distinct predicted values on training set for XGBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for XGBoost Classifier: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "combined_features_df = pd.read_csv('combined_features_exp_2.csv')\n",
    "df_transformed = pd.read_csv('transformed_data_exp_2.csv')\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = combined_features_df\n",
    "y = df_transformed['score'] - 1  # Adjust class labels to start from 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    #'Random Forest Classifier': RandomForestClassifier(n_estimators=600, max_depth=4, random_state=42),\n",
    "    #'AdaBoost Classifier': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'CatBoost Classifier': CatBoostClassifier(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Classifier': XGBClassifier(objective='multi:softmax', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Classifier': LGBMClassifier(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on training set for {name}: {np.unique(y_train_pred)}\")\n",
    "    kappa_train_score = cohen_kappa_score(y_train + 1, y_train_pred, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on test set for {name}: {np.unique(y_test_pred)}\")\n",
    "    kappa_test_score = cohen_kappa_score(y_test + 1, y_test_pred, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a44d4a63-ac69-40cb-af88-311c2a27fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  QWK Score (Train)  QWK Score (Test)\n",
      "1   XGBoost Classifier           0.995851          0.854455\n",
      "0  CatBoost Classifier           0.902166          0.851082\n"
     ]
    }
   ],
   "source": [
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(by='QWK Score (Test)', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677ecd8-1a38-4aa3-9e15-74959902ecdc",
   "metadata": {},
   "source": [
    "## Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fb7c5-78b8-4634-b89b-a19243c1f283",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1612cb9d-ce9a-49c1-af5f-414ae1b7eeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on Linear Regression...\n",
      "Elapsed time for Linear Regression: 0.014182329177856445 seconds\n",
      "Working on Random Forest Regressor...\n",
      "Elapsed time for Random Forest Regressor: 16.106038808822632 seconds\n",
      "Working on AdaBoost Regressor...\n",
      "Elapsed time for AdaBoost Regressor: 0.6758365631103516 seconds\n",
      "Working on CatBoost Regressor...\n",
      "Elapsed time for CatBoost Regressor: 1.6053357124328613 seconds\n",
      "Working on XGBoost Regressor...\n",
      "Elapsed time for XGBoost Regressor: 0.6350545883178711 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the training and test datasets\n",
    "df = pd.read_csv('numeric_features_added_exp_2.csv')\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = [\n",
    "    'reading_time',\n",
    "    'mistakes_dist_ratio',\n",
    "    'polysyllabcount',\n",
    "    'sentence_count',\n",
    "    'difficult_words',\n",
    "    'comma_count',\n",
    "    'transitional_phrases_c',\n",
    "    'text_dist_words_ratio'\n",
    "]\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = df[numerical_features]\n",
    "y = df['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(n_estimators=600, max_depth=4, random_state=42),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'CatBoost Regressor': CatBoostRegressor(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Regressor': XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Regressor': LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_scaled = (y_train_pred - y_train_pred.min()) / (y_train_pred.max() - y_train_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_train_discretized = discretize_predictions(y_train, target_classes)\n",
    "    y_train_pred_discretized = discretize_predictions(y_train_pred_scaled, target_classes)\n",
    "    kappa_train_score = cohen_kappa_score(y_train_discretized, y_train_pred_discretized, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_scaled = (y_test_pred - y_test_pred.min()) / (y_test_pred.max() - y_test_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_test_discretized = discretize_predictions(y_test, target_classes)\n",
    "    y_test_pred_discretized = discretize_predictions(y_test_pred_scaled, target_classes)\n",
    "    kappa_test_score = cohen_kappa_score(y_test_discretized, y_test_pred_discretized, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a1ce027-5284-4bcf-8cf3-d4412b5ff5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  QWK Score (Train)  QWK Score (Test)\n",
      "0        Linear Regression           0.500947          0.643906\n",
      "1  Random Forest Regressor           0.800033          0.799370\n",
      "2       AdaBoost Regressor           0.791092          0.792753\n",
      "3       CatBoost Regressor           0.847720          0.832627\n",
      "4        XGBoost Regressor           0.850914          0.834900\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91058eed-8c96-4a81-b054-57d848a2133e",
   "metadata": {},
   "source": [
    "### TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d2af201-da3b-4f56-ad1c-add5d301dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on Linear Regression...\n",
      "Elapsed time for Linear Regression: 2.2922353744506836 seconds\n",
      "Working on CatBoost Regressor...\n",
      "Elapsed time for CatBoost Regressor: 14.47586464881897 seconds\n",
      "Working on XGBoost Regressor...\n",
      "Elapsed time for XGBoost Regressor: 33.5309784412384 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df_transformed = pd.read_csv('transformed_data_exp_2.csv')\n",
    "df_tfidf = pd.read_csv('tfidf_features_exp_2.csv')\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = df_tfidf\n",
    "y = df_transformed['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    # 'Random Forest Regressor': RandomForestRegressor(n_estimators=600, max_depth=4, random_state=42),\n",
    "    # 'AdaBoost Regressor': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'CatBoost Regressor': CatBoostRegressor(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Regressor': XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Regressor': LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_scaled = (y_train_pred - y_train_pred.min()) / (y_train_pred.max() - y_train_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_train_discretized = discretize_predictions(y_train, target_classes)\n",
    "    y_train_pred_discretized = discretize_predictions(y_train_pred_scaled, target_classes)\n",
    "    kappa_train_score = cohen_kappa_score(y_train_discretized, y_train_pred_discretized, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_scaled = (y_test_pred - y_test_pred.min()) / (y_test_pred.max() - y_test_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_test_discretized = discretize_predictions(y_test, target_classes)\n",
    "    y_test_pred_discretized = discretize_predictions(y_test_pred_scaled, target_classes)\n",
    "    kappa_test_score = cohen_kappa_score(y_test_discretized, y_test_pred_discretized, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eab6d8a7-76cf-4e90-b18a-279eaff8a89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  QWK Score (Train)  QWK Score (Test)\n",
      "0   Linear Regression           0.690214          0.693764\n",
      "1  CatBoost Regressor           0.807107          0.718420\n",
      "2   XGBoost Regressor           0.901976          0.699006\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b278675-2ab9-43b4-b1f7-4765c275817d",
   "metadata": {},
   "source": [
    "### Combined Numerical and TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fb60408-0d9a-4732-b81d-6f87e4700744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on Linear Regression...\n",
      "Elapsed time for Linear Regression: 2.24367618560791 seconds\n",
      "Working on CatBoost Regressor...\n",
      "Elapsed time for CatBoost Regressor: 14.668799638748169 seconds\n",
      "Working on XGBoost Regressor...\n",
      "Elapsed time for XGBoost Regressor: 34.756917238235474 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "combined_features_df = pd.read_csv('combined_features_exp_2.csv')\n",
    "df_transformed = pd.read_csv('transformed_data_exp_2.csv')\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = combined_features_df\n",
    "y = df_transformed['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    #'Random Forest Regressor': RandomForestRegressor(n_estimators=600, max_depth=4, random_state=42),\n",
    "    #'AdaBoost Regressor': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'CatBoost Regressor': CatBoostRegressor(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Regressor': XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Regressor': LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_scaled = (y_train_pred - y_train_pred.min()) / (y_train_pred.max() - y_train_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_train_discretized = discretize_predictions(y_train, target_classes)\n",
    "    y_train_pred_discretized = discretize_predictions(y_train_pred_scaled, target_classes)\n",
    "    kappa_train_score = cohen_kappa_score(y_train_discretized, y_train_pred_discretized, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_scaled = (y_test_pred - y_test_pred.min()) / (y_test_pred.max() - y_test_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_test_discretized = discretize_predictions(y_test, target_classes)\n",
    "    y_test_pred_discretized = discretize_predictions(y_test_pred_scaled, target_classes)\n",
    "    kappa_test_score = cohen_kappa_score(y_test_discretized, y_test_pred_discretized, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b492c254-51b0-4e46-a200-c74288381564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  QWK Score (Train)  QWK Score (Test)\n",
      "0   Linear Regression           0.758918          0.781659\n",
      "1  CatBoost Regressor           0.904795          0.861679\n",
      "2   XGBoost Regressor           0.949607          0.864658\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa272913-2d3e-476e-b4d3-3230fe73e860",
   "metadata": {},
   "source": [
    "## Word2Vect features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1d85d-6041-46e1-91d7-40bf10063296",
   "metadata": {},
   "source": [
    "#### Option 1: Traditional Machine Learning Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fc0a334-13a3-4045-8d49-238585ee0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "1    4294\n",
      "2    4017\n",
      "3    2513\n",
      "4    2194\n",
      "0     854\n",
      "5     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "1    1074\n",
      "2    1005\n",
      "3     628\n",
      "4     548\n",
      "0     214\n",
      "5     142\n",
      "Name: count, dtype: int64\n",
      "Working on Random Forest Classifier...\n",
      "Elapsed time for Random Forest Classifier: 303.306348323822 seconds\n",
      "Distinct predicted values on training set for Random Forest Classifier: [2 3 5]\n",
      "Distinct predicted values on test set for Random Forest Classifier: [2 3 5]\n",
      "Working on AdaBoost Classifier...\n",
      "Elapsed time for AdaBoost Classifier: 387.48888397216797 seconds\n",
      "Distinct predicted values on training set for AdaBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for AdaBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on CatBoost Classifier...\n",
      "Elapsed time for CatBoost Classifier: 56.398645639419556 seconds\n",
      "Distinct predicted values on training set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for CatBoost Classifier: [1 2 3 4 5 6]\n",
      "Working on XGBoost Classifier...\n",
      "Elapsed time for XGBoost Classifier: 151.97435808181763 seconds\n",
      "Distinct predicted values on training set for XGBoost Classifier: [1 2 3 4 5 6]\n",
      "Distinct predicted values on test set for XGBoost Classifier: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# Load the datasets\n",
    "embeddings_df = pd.read_csv('word2vec_features_exp_2.csv')\n",
    "\n",
    "# Function to convert space-separated string of numbers (with brackets) to a list of floats\n",
    "def convert_to_list(embedding_str):\n",
    "    # Remove the square brackets\n",
    "    embedding_str = embedding_str.replace('[', '').replace(']', '')\n",
    "    # Split the string by spaces and convert to list of floats\n",
    "    return [float(num) for num in embedding_str.split()]\n",
    "\n",
    "# Apply the function to the word2vec_embedding column\n",
    "embeddings_df['word2vec_embedding'] = embeddings_df['word2vec_embedding'].apply(convert_to_list)\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = np.vstack(embeddings_df['word2vec_embedding'].values)\n",
    "y = embeddings_df['score'] - 1  # Adjust class labels to start from 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=600, max_depth=4, random_state=42),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'CatBoost Classifier': CatBoostClassifier(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Classifier': XGBClassifier(objective='multi:softmax', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Classifier': LGBMClassifier(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on training set for {name}: {np.unique(y_train_pred)}\")\n",
    "    kappa_train_score = cohen_kappa_score(y_train + 1, y_train_pred, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test) + 1  # Adjust predictions back to original scale\n",
    "    print(f\"Distinct predicted values on test set for {name}: {np.unique(y_test_pred)}\")\n",
    "    kappa_test_score = cohen_kappa_score(y_test + 1, y_test_pred, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be4254cf-cbb9-4b80-ba3b-3e3077576e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  QWK Score (Train)  QWK Score (Test)\n",
      "3        XGBoost Classifier           0.918547          0.733207\n",
      "2       CatBoost Classifier           0.785205          0.706903\n",
      "1       AdaBoost Classifier           0.643776          0.627829\n",
      "0  Random Forest Classifier           0.542995          0.534292\n"
     ]
    }
   ],
   "source": [
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(by='QWK Score (Test)', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdd6f0-6e0e-4d18-8f1e-31344d022908",
   "metadata": {},
   "source": [
    "#### Option 2: Traditional Machine Learning Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d656861c-7d4c-4a2d-ba0e-c5c5b7ae8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on Linear Regression...\n",
      "Elapsed time for Linear Regression: 4.015959739685059 seconds\n",
      "Working on CatBoost Regressor...\n",
      "Elapsed time for CatBoost Regressor: 23.43088173866272 seconds\n",
      "Working on XGBoost Regressor...\n",
      "Elapsed time for XGBoost Regressor: 31.195597887039185 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# Load the datasets\n",
    "embeddings_df = pd.read_csv('word2vec_features_exp_2.csv')\n",
    "\n",
    "# Function to convert space-separated string of numbers (with brackets) to a list of floats\n",
    "def convert_to_list(embedding_str):\n",
    "    # Remove the square brackets\n",
    "    embedding_str = embedding_str.replace('[', '').replace(']', '')\n",
    "    # Split the string by spaces and convert to list of floats\n",
    "    return [float(num) for num in embedding_str.split()]\n",
    "\n",
    "# Apply the function to the word2vec_embedding column\n",
    "embeddings_df['word2vec_embedding'] = embeddings_df['word2vec_embedding'].apply(convert_to_list)\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = np.vstack(embeddings_df['word2vec_embedding'].values)\n",
    "y = embeddings_df['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    #'Random Forest Regressor': RandomForestRegressor(n_estimators=600, max_depth=4, random_state=42),\n",
    "    #'AdaBoost Regressor': AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    'CatBoost Regressor': CatBoostRegressor(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True),\n",
    "    'XGBoost Regressor': XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=10, n_estimators=600),\n",
    "    #'LightGBM Regressor': LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=4, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for {name}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_scaled = (y_train_pred - y_train_pred.min()) / (y_train_pred.max() - y_train_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_train_discretized = discretize_predictions(y_train, target_classes)\n",
    "    y_train_pred_discretized = discretize_predictions(y_train_pred_scaled, target_classes)\n",
    "    kappa_train_score = cohen_kappa_score(y_train_discretized, y_train_pred_discretized, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_scaled = (y_test_pred - y_test_pred.min()) / (y_test_pred.max() - y_test_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_test_discretized = discretize_predictions(y_test, target_classes)\n",
    "    y_test_pred_discretized = discretize_predictions(y_test_pred_scaled, target_classes)\n",
    "    kappa_test_score = cohen_kappa_score(y_test_discretized, y_test_pred_discretized, weights='quadratic')\n",
    "\n",
    "    results.append({'Model': name, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a7f0c32-9acf-42a4-a6e9-c45c8f468a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  QWK Score (Train)  QWK Score (Test)\n",
      "0   Linear Regression           0.595021          0.622043\n",
      "1  CatBoost Regressor           0.739214          0.678438\n",
      "2   XGBoost Regressor           0.813884          0.685875\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe861dc-2505-416a-be14-538d9311f1ba",
   "metadata": {},
   "source": [
    "#### Option 3: Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e8cf6d-c6b6-47c2-a69c-a964103d85be",
   "metadata": {},
   "source": [
    "A simple feedforward neural network using TensorFlow Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "538e6726-bf85-48dc-a47a-6cd6d184e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dziya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "452/452 - 12s - 27ms/step - loss: 1.8031 - val_loss: 1.1005\n",
      "Epoch 2/50\n",
      "452/452 - 4s - 8ms/step - loss: 1.1389 - val_loss: 1.0990\n",
      "Epoch 3/50\n",
      "452/452 - 3s - 6ms/step - loss: 1.0602 - val_loss: 1.0839\n",
      "Epoch 4/50\n",
      "452/452 - 3s - 7ms/step - loss: 0.9994 - val_loss: 0.9974\n",
      "Epoch 5/50\n",
      "452/452 - 3s - 8ms/step - loss: 0.9648 - val_loss: 1.0961\n",
      "Epoch 6/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.9273 - val_loss: 0.9902\n",
      "Epoch 7/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.9125 - val_loss: 1.0044\n",
      "Epoch 8/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8817 - val_loss: 0.8196\n",
      "Epoch 9/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8582 - val_loss: 0.8983\n",
      "Epoch 10/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8417 - val_loss: 0.8315\n",
      "Epoch 11/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8402 - val_loss: 0.7980\n",
      "Epoch 12/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8243 - val_loss: 0.8603\n",
      "Epoch 13/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8143 - val_loss: 0.9262\n",
      "Epoch 14/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.8028 - val_loss: 0.8140\n",
      "Epoch 15/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7974 - val_loss: 0.7595\n",
      "Epoch 16/50\n",
      "452/452 - 4s - 9ms/step - loss: 0.7870 - val_loss: 0.7497\n",
      "Epoch 17/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7779 - val_loss: 0.7516\n",
      "Epoch 18/50\n",
      "452/452 - 2s - 4ms/step - loss: 0.7703 - val_loss: 0.7938\n",
      "Epoch 19/50\n",
      "452/452 - 3s - 8ms/step - loss: 0.7549 - val_loss: 0.7496\n",
      "Epoch 20/50\n",
      "452/452 - 3s - 8ms/step - loss: 0.7524 - val_loss: 0.7759\n",
      "Epoch 21/50\n",
      "452/452 - 3s - 7ms/step - loss: 0.7504 - val_loss: 0.7377\n",
      "Epoch 22/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7458 - val_loss: 0.7445\n",
      "Epoch 23/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7398 - val_loss: 0.7617\n",
      "Epoch 24/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7343 - val_loss: 0.8102\n",
      "Epoch 25/50\n",
      "452/452 - 4s - 9ms/step - loss: 0.7262 - val_loss: 0.7217\n",
      "Epoch 26/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7214 - val_loss: 0.7199\n",
      "Epoch 27/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7042 - val_loss: 0.7150\n",
      "Epoch 28/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7089 - val_loss: 0.6995\n",
      "Epoch 29/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.7014 - val_loss: 0.7054\n",
      "Epoch 30/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6965 - val_loss: 0.6818\n",
      "Epoch 31/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6984 - val_loss: 0.7172\n",
      "Epoch 32/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6971 - val_loss: 0.6914\n",
      "Epoch 33/50\n",
      "452/452 - 3s - 6ms/step - loss: 0.6770 - val_loss: 0.6770\n",
      "Epoch 34/50\n",
      "452/452 - 4s - 9ms/step - loss: 0.6837 - val_loss: 0.6692\n",
      "Epoch 35/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6713 - val_loss: 0.6894\n",
      "Epoch 36/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6625 - val_loss: 0.6873\n",
      "Epoch 37/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6606 - val_loss: 0.6699\n",
      "Epoch 38/50\n",
      "452/452 - 3s - 8ms/step - loss: 0.6611 - val_loss: 0.7077\n",
      "Epoch 39/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6567 - val_loss: 0.6814\n",
      "Epoch 40/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6575 - val_loss: 0.6539\n",
      "Epoch 41/50\n",
      "452/452 - 3s - 8ms/step - loss: 0.6550 - val_loss: 0.6893\n",
      "Epoch 42/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6550 - val_loss: 0.6746\n",
      "Epoch 43/50\n",
      "452/452 - 4s - 9ms/step - loss: 0.6430 - val_loss: 0.6556\n",
      "Epoch 44/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6391 - val_loss: 0.6625\n",
      "Epoch 45/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6355 - val_loss: 0.6671\n",
      "Epoch 46/50\n",
      "452/452 - 4s - 8ms/step - loss: 0.6420 - val_loss: 0.6996\n",
      "Epoch 47/50\n",
      "452/452 - 4s - 9ms/step - loss: 0.6267 - val_loss: 0.6635\n",
      "Epoch 48/50\n",
      "452/452 - 2s - 5ms/step - loss: 0.6322 - val_loss: 0.6612\n",
      "Epoch 49/50\n",
      "452/452 - 2s - 5ms/step - loss: 0.6236 - val_loss: 0.6558\n",
      "Epoch 50/50\n",
      "452/452 - 2s - 5ms/step - loss: 0.6188 - val_loss: 0.6294\n",
      "\u001b[1m452/452\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "QWK Score on Train Set: 0.7835543338347906\n",
      "QWK Score on Test Set: 0.7417995009012259\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "embeddings_df = pd.read_csv('word2vec_features_exp_2.csv')\n",
    "\n",
    "# Function to convert space-separated string of numbers (with brackets) to a list of floats\n",
    "def convert_to_list(embedding_str):\n",
    "    # Remove the square brackets\n",
    "    embedding_str = embedding_str.replace('[', '').replace(']', '')\n",
    "    # Split the string by spaces and convert to list of floats\n",
    "    return [float(num) for num in embedding_str.split()]\n",
    "\n",
    "# Apply the function to the word2vec_embedding column\n",
    "embeddings_df['word2vec_embedding'] = embeddings_df['word2vec_embedding'].apply(convert_to_list)\n",
    "\n",
    "print(\"Working on Split, Train, Validate\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Split Data\n",
    "X = np.vstack(embeddings_df['word2vec_embedding'].values)\n",
    "y = embeddings_df['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dynamically determine target classes\n",
    "target_classes = np.sort(np.unique(y))\n",
    "\n",
    "# Check the distribution of the target classes in the training data\n",
    "print(\"Distribution of target classes in the training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Check the distribution of the target classes in the test data\n",
    "print(\"Distribution of target classes in the test data:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Standardize data for neural networks\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=2)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = model.predict(X_train_scaled).flatten()\n",
    "y_test_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "# Define the QWK computation function\n",
    "def compute_qwk(y_true, y_pred, target_classes):\n",
    "    y_pred_discretized = discretize_predictions(y_pred, target_classes)\n",
    "    return cohen_kappa_score(y_true, y_pred_discretized, weights='quadratic')\n",
    "\n",
    "# Evaluate using QWK score\n",
    "qwk_train = compute_qwk(y_train, y_train_pred, target_classes)\n",
    "qwk_test = compute_qwk(y_test, y_test_pred, target_classes)\n",
    "\n",
    "print(f\"QWK Score on Train Set: {qwk_train}\")\n",
    "print(f\"QWK Score on Test Set: {qwk_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949be7a-0fdd-412f-b9e4-351a2707aa60",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410564ba-4326-49d9-aaac-31874995911f",
   "metadata": {},
   "source": [
    "- **Run Time and Resource Usage:** The BERT model occupied much resources and required several hours to run, leading to the decision to abandon this approach due to impracticality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d7de8-c91b-4382-aeae-2778a2cbdd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
