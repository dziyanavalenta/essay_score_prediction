{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215cc776-0b76-4c37-9cf6-89d6a0a1013d",
   "metadata": {},
   "source": [
    "TF-IDF Dimensionality Reduction: Consider reducing dimensionality while retaining essential information by applying PCA. This could help mitigate overfitting and improve model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75503dfa-1aca-4d8c-ba61-437d710d0eac",
   "metadata": {},
   "source": [
    "## Performance Evaluation of CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84d0eb9-18a7-4186-a3ef-f691366cdeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Split, Train, Validate for combined_features_exp_2.csv\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on CatBoost Regressor for combined_features_exp_2.csv...\n",
      "Elapsed time for CatBoost Regressor on combined_features_exp_2.csv: 15.531715869903564 seconds\n",
      "Working on Split, Train, Validate for combined_features_exp_2_pca_1000.csv\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on CatBoost Regressor for combined_features_exp_2_pca_1000.csv...\n",
      "Elapsed time for CatBoost Regressor on combined_features_exp_2_pca_1000.csv: 11.87550163269043 seconds\n",
      "Working on Split, Train, Validate for combined_features_exp_2_pca_700.csv\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on CatBoost Regressor for combined_features_exp_2_pca_700.csv...\n",
      "Elapsed time for CatBoost Regressor on combined_features_exp_2_pca_700.csv: 9.107178688049316 seconds\n",
      "Working on Split, Train, Validate for combined_features_exp_2_pca_500.csv\n",
      "Distribution of target classes in the training data:\n",
      "score\n",
      "2    4294\n",
      "3    4017\n",
      "4    2513\n",
      "5    2194\n",
      "1     854\n",
      "6     568\n",
      "Name: count, dtype: int64\n",
      "Distribution of target classes in the test data:\n",
      "score\n",
      "2    1074\n",
      "3    1005\n",
      "4     628\n",
      "5     548\n",
      "1     214\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Working on CatBoost Regressor for combined_features_exp_2_pca_500.csv...\n",
      "Elapsed time for CatBoost Regressor on combined_features_exp_2_pca_500.csv: 7.788886070251465 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from catboost import CatBoostRegressor\n",
    "import time\n",
    "\n",
    "# List of datasets to process\n",
    "datasets = [\n",
    "    'combined_features_exp_2.csv',\n",
    "    'combined_features_exp_2_pca_1000.csv',\n",
    "    'combined_features_exp_2_pca_700.csv',\n",
    "    'combined_features_exp_2_pca_500.csv'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Function to discretize predictions\n",
    "def discretize_predictions(predictions, target_classes):\n",
    "    bins = np.linspace(min(target_classes) - 0.5, max(target_classes) + 0.5, num=len(target_classes) + 1)\n",
    "    discretized = np.digitize(predictions, bins) - 1\n",
    "    discretized = np.clip(discretized, 0, len(target_classes) - 1)\n",
    "    return discretized + 1\n",
    "\n",
    "# Process each dataset\n",
    "for dataset in datasets:\n",
    "    # Load the datasets\n",
    "    combined_features_df = pd.read_csv(dataset)\n",
    "    df_transformed = pd.read_csv('transformed_data_exp_2.csv')\n",
    "\n",
    "    print(f\"Working on Split, Train, Validate for {dataset}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Split Data\n",
    "    X = combined_features_df\n",
    "    y = df_transformed['score']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Check the distribution of the target classes in the training data\n",
    "    print(\"Distribution of target classes in the training data:\")\n",
    "    print(y_train.value_counts())\n",
    "\n",
    "    # Check the distribution of the target classes in the test data\n",
    "    print(\"Distribution of target classes in the test data:\")\n",
    "    print(y_test.value_counts())\n",
    "\n",
    "    # Define the CatBoost Regressor model\n",
    "    model = CatBoostRegressor(iterations=600, depth=4, learning_rate=0.1, random_seed=42, silent=True)\n",
    "\n",
    "    target_classes = np.sort(np.unique(y))\n",
    "\n",
    "    print(f\"Working on CatBoost Regressor for {dataset}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time for CatBoost Regressor on {dataset}: {end_time - start_time} seconds\")\n",
    "\n",
    "    # Predictions on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_scaled = (y_train_pred - y_train_pred.min()) / (y_train_pred.max() - y_train_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_train_discretized = discretize_predictions(y_train, target_classes)\n",
    "    y_train_pred_discretized = discretize_predictions(y_train_pred_scaled, target_classes)\n",
    "    kappa_train_score = cohen_kappa_score(y_train_discretized, y_train_pred_discretized, weights='quadratic')\n",
    "\n",
    "    # Predictions on test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_scaled = (y_test_pred - y_test_pred.min()) / (y_test_pred.max() - y_test_pred.min()) * (y_train.max() - y_train.min()) + y_train.min()\n",
    "    y_test_discretized = discretize_predictions(y_test, target_classes)\n",
    "    y_test_pred_discretized = discretize_predictions(y_test_pred_scaled, target_classes)\n",
    "    kappa_test_score = cohen_kappa_score(y_test_discretized, y_test_pred_discretized, weights='quadratic')\n",
    "\n",
    "    results.append({'Dataset': dataset, 'QWK Score (Train)': kappa_train_score, 'QWK Score (Test)': kappa_test_score})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a18d7-cbe7-4bc9-872a-ccd13ac636f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355c0ab3-dd2e-45d1-aff4-2c837afc694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Dataset  QWK Score (Train)  QWK Score (Test)\n",
      "0           combined_features_exp_2.csv           0.904795          0.861679\n",
      "1  combined_features_exp_2_pca_1000.csv           0.906795          0.862143\n",
      "2   combined_features_exp_2_pca_700.csv           0.906436          0.862702\n",
      "3   combined_features_exp_2_pca_500.csv           0.902056          0.867482\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d4d1e-470c-41fa-8b25-5d6fc46da5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
